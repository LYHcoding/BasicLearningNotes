# 机器学习探讨内容—第三周

Created: July 13, 2022 → July 20, 2022
Status: In Progress
Type: discuss

**本周主要学习内容：**

代码结合理论的实现，并结合sklearn里的svm svc svr超参数理解下这些怎么调。

> **Sklearn 中文文档**
> 
> 
> [支持向量机](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8E%A2%E8%AE%A8%E5%86%85%E5%AE%B9%E2%80%94%E7%AC%AC%E4%B8%89%E5%91%A8%203e51a375ef9941aca3423ec2788e3caf/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%208fa1338de2434c76bc5d9a3568b5d314.md)
> 
> ****scikit-learn中文社区****
> 
> [scikit-learn中文社区](https://scikit-learn.org.cn/)
> 

# Topic:   支持向量机

支持向量机（Support Vector Machine, SVM）是一类按监督学习（supervised learning）方式对数据进行二元分类的广义线性分类器（generalized linear classifier），其决策边界是对学习样本求解的最大边距超平面（maximum-margin hyperplane） 。

![Untitled](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8E%A2%E8%AE%A8%E5%86%85%E5%AE%B9%E2%80%94%E7%AC%AC%E4%B8%89%E5%91%A8%203e51a375ef9941aca3423ec2788e3caf/Untitled.png)

> sklearn (scikit-learn) 是基于 Python 语言的机器学习工具。
> 
> 1. 简单高效的数据挖掘和数据分析工具
> 2. 可供大家在各种环境中重复使用
> 3. 建立在 NumPy ，SciPy 和 matplotlib 上
> 4. 开源，可商业使用
- **cf：svm svc svr**
    - SVM=Support Vector Machine 是支持向量机
    - SVC=Support Vector Classification 就是支持向量机用于分类，
    - SVR=Support Vector Regression 就是支持向量机用于回归分析

![Untitled](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8E%A2%E8%AE%A8%E5%86%85%E5%AE%B9%E2%80%94%E7%AC%AC%E4%B8%89%E5%91%A8%203e51a375ef9941aca3423ec2788e3caf/Untitled%201.png)

**SVM 中经典问题：函数间隔为什么可以设为1？**

函数间隔就是每个样本点到超平面的相对距离—r^。

几何间隔就是每个样本点到超平面的绝对距离—r。

![Untitled](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8E%A2%E8%AE%A8%E5%86%85%E5%AE%B9%E2%80%94%E7%AC%AC%E4%B8%89%E5%91%A8%203e51a375ef9941aca3423ec2788e3caf/Untitled%202.png)

几何间隔其实就是在函数间隔的基础上施加了一个约束限制。

- 对最大间隔公式进行优化推理过程中，将函数间隔设为1，即下属将公式9.13转化为式9.14：
    
    ![Untitled](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8E%A2%E8%AE%A8%E5%86%85%E5%AE%B9%E2%80%94%E7%AC%AC%E4%B8%89%E5%91%A8%203e51a375ef9941aca3423ec2788e3caf/Untitled%203.png)
    
    ![Untitled](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8E%A2%E8%AE%A8%E5%86%85%E5%AE%B9%E2%80%94%E7%AC%AC%E4%B8%89%E5%91%A8%203e51a375ef9941aca3423ec2788e3caf/Untitled%204.png)
    
    ![Untitled](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8E%A2%E8%AE%A8%E5%86%85%E5%AE%B9%E2%80%94%E7%AC%AC%E4%B8%89%E5%91%A8%203e51a375ef9941aca3423ec2788e3caf/Untitled%205.png)
    
    以上可以发现，约束条件由几何间隔变成了函数间隔，准确说应该既是函数间隔同样也是几何间隔。因此，既然可以看作函数间隔，那么令γ^=1自然也不会影响最终的优化结果。
    
    - 函数间隔可以设为1的原因：
        
        假设现在有如下函数间隔
        
        ![Untitled](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8E%A2%E8%AE%A8%E5%86%85%E5%AE%B9%E2%80%94%E7%AC%AC%E4%B8%89%E5%91%A8%203e51a375ef9941aca3423ec2788e3caf/Untitled%206.png)
        
        那么对等式9.16两边同时除以γ^便有
        
        ![Untitled](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8E%A2%E8%AE%A8%E5%86%85%E5%AE%B9%E2%80%94%E7%AC%AC%E4%B8%89%E5%91%A8%203e51a375ef9941aca3423ec2788e3caf/Untitled%207.png)
        
        此时令W=w/γ^,B=b/γ^，便可以将9.17转化为
        
        ![Untitled](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8E%A2%E8%AE%A8%E5%86%85%E5%AE%B9%E2%80%94%E7%AC%AC%E4%B8%89%E5%91%A8%203e51a375ef9941aca3423ec2788e3caf/Untitled%208.png)
        
        接着再把式9.18中的W,B换成w,b即可得到
        
        ![Untitled](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8E%A2%E8%AE%A8%E5%86%85%E5%AE%B9%E2%80%94%E7%AC%AC%E4%B8%89%E5%91%A8%203e51a375ef9941aca3423ec2788e3caf/Untitled%209.png)
        
        不过需要明白的是，式9.16和式9.19中的w,b并不是同一个。
        
        虽然此时的w,b同时都缩小或放大相同的倍数，函数间隔变成了1，但是函数缩小或放大前后所表示的依旧是同一个超平面。因此可以将函数间隔直接设为1（实质是同时除以一个函数间隔）。
        
    - 举例说明：
        
        例如现有如下平面方程
        
        ![Untitled](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8E%A2%E8%AE%A8%E5%86%85%E5%AE%B9%E2%80%94%E7%AC%AC%E4%B8%89%E5%91%A8%203e51a375ef9941aca3423ec2788e3caf/Untitled%2010.png)
        
        某正样本y(k)=+1的函数间隔为γ^(k)=2，所以有
        
        ![Untitled](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8E%A2%E8%AE%A8%E5%86%85%E5%AE%B9%E2%80%94%E7%AC%AC%E4%B8%89%E5%91%A8%203e51a375ef9941aca3423ec2788e3caf/Untitled%2011.png)
        
        进一步在等式9.21两边同时除以2有
        
        ![Untitled](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8E%A2%E8%AE%A8%E5%86%85%E5%AE%B9%E2%80%94%E7%AC%AC%E4%B8%89%E5%91%A8%203e51a375ef9941aca3423ec2788e3caf/Untitled%2012.png)
        

**Tips：**

- 抓取参考的SVM网页内容：
    
    [从原理到代码实现入门支持向量机（SVM）](https://www.notion.so/SVM-c67aa7fe937e4719be300099edb11948)
    
    [支持向量机：白板推导 + 代码实现 - 知乎](https://www.notion.so/1fc01a34a7e144feb0de171f4cb3acff)
    
    [详解支持向量机（SVM）算法与代码实现 - 知乎](https://www.notion.so/SVM-0fb343d2449944e89e8e379b3d3edf5b)
    

- ****sklearn.svm.SVC参数详解****
    
    [sklearn.svm.SVC参数详解](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8E%A2%E8%AE%A8%E5%86%85%E5%AE%B9%E2%80%94%E7%AC%AC%E4%B8%89%E5%91%A8%203e51a375ef9941aca3423ec2788e3caf/sklearn%20svm%20SVC%E5%8F%82%E6%95%B0%E8%AF%A6%E8%A7%A3%200abaf56a0768483a9f1d3ea7b62defcf.md)
    

- 结合理论实现代码，从而理解调参。
    
    参考
    
    [支持向量机SVM--sklearn.svm.SVC【机器学习笔记简摘】](https://zhuanlan.zhihu.com/p/538019344)
    
    我的代码笔记
    
    [BasicLearningNotes/SVM.ipynb at main · LYHcoding/BasicLearningNotes](https://github.com/LYHcoding/BasicLearningNotes/blob/main/SVM/SVM.ipynb)
    

- 后面需要自己搭建SVM模型，加深理解

<aside>
📌 **SUMMARY: 先学习了SVM算法原理，然后结合理论实现代码，并结合sklearn学习理解怎么调整svm中C、kernel、degree、gamma等超参数。**

</aside>

---